import os
import numpy as np
import soundfile as sf
from sklearn.decomposition import NMF
import librosa

# Function to load and preprocess audio data for NMF
def load_and_preprocess_audio(audio_file_path):
    audio, sample_rate = librosa.load(audio_file_path, sr=None, mono=False)
    if audio.ndim > 1:
        audio = np.mean(audio, axis=0)
    audio /= np.max(np.abs(audio))
    return audio, sample_rate

# Define the path to the LibriSpeech dataset (change it according to your directory)
librispeech_path = 'D:/Datasets/LibriSpeech_dataset'

# Function to get paths to all audio files in the LibriSpeech dataset
def get_audio_files(dataset_path):
    audio_files = []
    for root, dirs, files in os.walk(dataset_path):
        for file in files:
            if file.endswith('.flac'):
                audio_files.append(os.path.join(root, file))
    return audio_files

# Get paths to all audio files in the LibriSpeech dataset
audio_files = get_audio_files(librispeech_path)

# Load and preprocess audio data
all_audio = []
for audio_file in audio_files:
    audio, sample_rate = load_and_preprocess_audio(audio_file)
    all_audio.append(audio)

mixed_audio = np.array(all_audio)
A = np.random.rand(len(audio_files), len(audio_files))
mixed_audio = np.dot(A, mixed_audio)

# Save the mixed audio (for illustration purposes)
sf.write('mixed_audio.wav', mixed_audio.T, sample_rate)

# Perform NMF on the mixed audio data to separate the sources
nmf = NMF(n_components=len(audio_files), init='random', random_state=0)  # Assuming all audio files are sources
W = nmf.fit_transform(np.abs(mixed_audio))
H = nmf.components_

# Reconstruct separated sources from the learned W and H matrices
separated_sources = np.dot(W, H)

# Save the separated sources to audio files (for illustration purposes)
for i, source in enumerate(separated_sources.T):
    sf.write(f'separated_source_{i + 1}.wav', source, sample_rate)
